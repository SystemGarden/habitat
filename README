SYSTEM GARDEN HABITAT
=====================

Welcome to System Garden Habitat, the monitoring and visualisation tool for
systems and applications.

VERSION 1.2.1
-------------

Restarting of daemon fixed and re-enabled in the job table every 24 hours.
Whilst we attempt to purge all memory and resource leaks, sometimes we 
need a little help :-). (Don't put forks() in atexits()!!) 
Reload the job table to take effect.

LICENSE
-------

System Garden has released Habitat under the Free Software Foundation's 
Gnu Public License version 2 (GPLv2).   Please look at the file LICENSE in the 
top directory for a full description of the GPL and to understand 
the legal position.  Do not use this software unless you understand 
and agree to the license.

CHANGES
-------
	VERSION 1.2.1
	- Restart method fixed and re-enabled
	- Signals now specifically unblocked on initialisation
	- Added a shutdown method
	- Clockwork command introduces -j and -J for jobs
	- Clockwork jobs now read from files not DB

	VERSION 1.2
	- Refactored replication code
	- Improved replication and http errors
	- Integration with harvest as repository for outbound replication
	- Text configuration aded to tableset for non programatic parameters
	- Added a filter to the process probe (ps) to reduce volume of
	  returned information
	- Table library bug for importing other tables found and fixed
	- Tableset now works in floating potint or interger context, so
	  the ps filter can have fp values in comparisons
	- Habprobe command default logging level changed to diagnostic
	- PS probe filter confguration added to lib
	- Fixed a string buffer bug
	- Fixed a 'no data' bug when extracting data for drawing
	- changed cascade_execute() to return 0 for success to be consistent
	- running clockwork -d reports simple 'success' or 'failure'
	- removed deprecated code (meth and tablestat)
	- upgraded probe row differencing to multi-instance
	- Create PTREE, a pointer-key'ed tree store
	- nmalloc, meth_b, meth_probe, gtkaction and callback refactored 
	  to use PTREE, 64-bit clean
	- 64-bit compliant type casting
	- Fixed hashes to work in 64-bit environment
	- Fixed occasional GUI bug when no hosts are returned from repository
	- Changed habprobe to use count (-n) and interval (-i)
	- Added restart method to respawn clockwork and save memory/resource
	  leaks, but disabled due to job table problems
	- New (but disabled) job to restart clockwork after 1d+2s
	- Daemons now double fork to rid themselves of controling terms
	- New memory leaks fixed
	- Makefiles tweeked to compile under Mac OS X and Mac Ports
	- Fixed a GUI bug with repository screen
	- ROUTE_BUFSZ set to 4096 as PIPE_BUF is small on MacOS X -- why?
	- Linker fixes to make Mac OS X behave like unix and linux
	- Disabled local collection (clockwork) on Mac OS X

	VERSION 1.1.1
	- Upgraded clock tick counters with 64 bit quantities for
	  longer run time in Linux
	- New recipe for calaculating %wait in Linux
	- New support for virtual machine inspired metrics in Linux 
	  (%steal & %guest)
	- Improved ugly fonts in some implementations of Gtk 1 (Ubuntu)

	VERSION 1.1
	- Tweeked the spaces in the choice node property window
	- Created repository parameter window
	- Window manager icon replace with new 'floppy' flower logo
	- Replaced spash logo with new harvest logo
	- Some icons in choice tree changes
	- added home directory expansion (%u) for some route names
	- fixed several small problems with habmeth and habprobe
	- More tuning off log messages
	- Changed all apps to route_expand() entire config on initialisation
	- Job table changed to file, not ringstore to allow for easier
	  config changes in the future of the client
	- Non-time data (like job table) redraw bug fixed and update
	  routine refactored
	- Sanitised a number log messages to make more clear to user
	- Added authurl for proxy and site credentials (default ~/.habauth)
	- Added cookiejar for session token (default ~/.habjar)
	- Added cookies for account security (default ~/.habcookies) 
	- Added basic authentication for site security
	- Established communication with Harvest 2.0 as READ-ONLY repository 
	  (see http://systemgarden.com/harvest)
	- Fixed a class of atoi() bug
	- Fixed charts when data suddenly becomes empty after a suspend
	- Window form to read, configure and write repository credentials
	  in ghabitat (File->Repository)
	- More efficient config line replacement
	- unset PROXY_HTTP, proxy_http env variable which affects libcurl
	- More saftey from zero length attributes within bigger table data
	- Selective use of proxy servers, used for repository, not used when
	  talking to clockwork on local machine
	- Better HTTP handling with improved timeouts and better errors
	- .habauth is saved is mode 600, but can be read in any mode

	VERSION 1.0.0
	- Process instance identifier changed from pid to one made up from
	  the command and the pid, and called 'process'.
	- Added similar solaris human readable process id
	- Changed the solaris I/O probe id to be the mount point if one exists
	- Changed button text in log popup window to 'Close' from 'OK'
	- Route p-urls now default to plain files if driver is not supplied
	- Logo pixmap changed to have a mask
	- Log popup now has a window manager logo
	- Log collection pulldown added to log popup window
	- Added menu items and keyboard accelerators to zoom in and out
	  of graph in addition to buttons and mouse rubberbanding
	- Limited accumulated data to the timebase selected
	- Fixed a small bug when consolidated ringstore requests can return
	  two data for a single time
	- Fixed a memory allocation bug during updates when removing 
	  expired data
	- Graph redraws made more efficient by rationalising the work
	- Zoom menu item added and accelerator keys for charts
	- Choice tree popup added for general and node specific functions
	- Property window added with expert and inherited options
	- Added dynamic chocie node update

INSTALLATION
------------

Copy the Habitat tree into an area of read write disk, which will need
around 50 MBytes free (the directory is referred to as $HAB in this readme). 

Once copied, check that there is ~40 MBytes of available storage which 
will be used for the data file. There should be permissions to create files 
for the user that will run the system ($HAB/var is written to).

No environment variables need to be set.

Thats it!

HOW TO START
------------

Just run the command 'ghabitat' inside $HAB/bin, which will start the 
Gtk GUI. You will be asked if you want to start local collection of 
data via a pop-up window. Click 'Collect data', which will start the 
back-end server and load the file into your data choice pane on the left.
The data file created will have your ownership default umask.

In the current release, the default data collection rate is every 60 
seconds, which keeps the impact to system load to a minimum. 
Unfortunately, this means that you will need to wait for two to three 
minutes for meaningful data to appear.

The 'ghabitat' window is divided into two, like an `explorer' type interface. 
On the left is a tree of data choices, on the right is a visualisation of 
the data that you select.

Once you are ready to look at the data, look for 'this host' under the
choice tree on the left. (You can also see the data under 'my files' 
in the tree, named <hostname>.rs, which is the filename the into which
data has been stored). Look at 'perf charts' and 'perf tables'.
Under either option, you will find data gathered from at least five probes:

symbols    - OS name data (run once at start up)
system     - processor & general system information
storage    - disk performance
network    - network collection
interrupts - hardware interrupts

Click on 'cpu', click on a timebase and a graph or table will be generated 
in the visualisation area in the right hand pane.

The choice tree will look a little like this (or will after some time):-

habitat
|
+ this host
| + uptime
| + perf charts
| | + symbols
| | + system
| | | + 5 minutes
| | | + 1 hour
| | | + 8 hours
| | | + 24 hours
| | | + 7 days
| | | + 2 weeks
| | + storage
| | + network
| | + interrupts
| + perf tables
| + events
| + logs
| + replication
| + jobs
| + data
+ my files
+ my hosts
+ repository
+ this client
  + configuration
  + log routes
  + logs


Under 'this client', you find application configuration, error routing
under 'log routes' and the message themselves as 'logs'.

LOOKING AT THE DATA
-------------------

Using 'perf table', the data section shows a table which can be 
scrolled horizontally and vertically. The opportunity to save or send
the data in various forms is given by the Data menu.

With 'perf chart' options, the viewing section is divided in two
for the graph and the curve buttons. A default selection of curves are
drawn, such as %work or %system in the sys probe. To select more or 
less curves, just click on the buttons which will colour code the curves
that are drawm.

If a multi instance probe is selected, like io (for disks) or net, then
the button secition is itself divided in two: the bottom for buttons and 
the top for instances. For example, each disk device will be a different 
instance, but each will have the same attributes (such as blocks read or 
filesystem capacity).

A useful feature of the graphs is the ability to zoom in. Either use the 
button box to the top right to zoom in and out, or drag a box round the 
area of graph in interest, then click inside it to zoom.

RUNNING STAND ALONE
-------------------

Habitat consists of a back end for data gathering called 'clockwork'
and a set of front ends for display and analysis of results, of which the
most useful is 'ghabitat'. If 'ghabitat' finds that 'clockwork' is not
running on the local system, it will ask if you wish to run it and
optionally leave it running.

However, to collect data on several machines, just run 'clockwork'
on each machine, which as a daemon will background itself and log its own
errors and warnings for later management. The data is saved in a file named 
after the local host in a standard location accessable by file sharing 
(NFS, SMB/CIFS, etc), and also publish it using a network service from
clockwork.

If there is a problem launching clockwork, starting

          $HAB/bin/clockwork -d

will cause diagnostic messages to be sent to stderr. Send this output to 
support@systemgarden.com. If there are still problems, execute the 
following line in conjunction with System Garden's support (as there 
is lot of gory detail here):-

          $HAB/bin/clockwork -D

This places clockwork into developer debug mode.

This will send all messages to stderr on the screen, including debug
information which will help in the diagnosis of the problem. Send this
information to support@systemgarden.com, too.

WHERE DOES EVERYTHING GO?
-------------------------

By convention (and default), everything is read from and written to 
a single file

          $HAV/var/<yourhost>.rs

where <host> is the name of your computer, obatined by typing 
`hostname' at a command prompt. Depending on configuration, the file name
may also include the domainname.

Inside this file are rings of data, one of which is a log file (`log') and
another is a set of directives (`clockwork'). The directives have a section
of their own below, but for now lets look at the log.

The command line utility 'irs' can be used to look at this data, or the 
'data' section of the tree will give a view to the raw data.

All the parts of habitat are configured in the same way, using 
$HAB/etc/habitat.conf and ~/.habrc. It can also be augmented from 
more central locations: see the manual page habconf(5).

PERFORMANCE GATHERING PROBES
----------------------------

A probe is a small piece of code inside or called by the back end 
`clockwork'. Its job is to sample data and potentially repackage it
for data display.

Select `perf charts' and at least two children appear: `symbols' 
and `system'. These are the names of the active probes running from 
`clockwork' and each probe generates data which we can view in different 
ways. If you were to write a probe, it would appear here.

If an item in the list is selected, it will change colour and a curve 
drawn in that colour in the graph display. Selecting multiple items will 
display multiple curves in appropreate colours.

TO EXIT THE FRONT END
---------------------

Type ^X or click on `File->Exit' to leave the application.

STOPPING CLOCKWORK NORMALLY AND WHAT TO EXPECT
----------------------------------------------

Clockwork is a daemon, detached from the command line.
As such, it is designed to stay runnning indefinitely, permanently 
recording your system's activities. There are no problems leaving it
to run as it always trys to curtail the amount to disk space used by
removing the oldest high frequency data, leaving lower frequency samples.

To stop clockwork from obtaining samples, use 'killclock'. This will 
find the lock file created from clockwork and attempts to send a
signal to the running process in order to end it.

From the 'ghabitat' GUI, select Collect->Local Data... from the menu
and stop local data collection from the pop-up window.

To restart, just run 'clockwork' from the command line or in 'ghabitat'
select 'Collect->Local Data...' from the menu and start it from the button.

OTHER COMMANDS
--------------
Other commands exists to complement the GUI and data collector.

	killclock - stop the clockwork daemon
	irs       - command line interface to ringstore storage & admin
	habget    - get data from a route
	habput    - send data to a route
	habedit   - edit a route or ringstore (useful for configuring
	            the jobs in clockwork)
	habmeth   - run a clockwork method manually
	habprobe  - run one of the built-in data gathering 
	            probe manually
	habrep    - run the replication procedure manually

DOCUMENTATION & NEXT STEPS
--------------------------
To learn more about habitat, look at the System Garden web site 
http://www.systemgarden.com/habitat. It gives information about the product 
and company and is the place to go to for new downloads and documentation. 

By clicking on `documentation' under the `habitat' heading, you
get overviews, presentations, white papers and manuals. As more is
written, it will be placed there, so check back periodically.

HARVEST
-------
If Habitat monitors and visualises low level data, Harvest aggregates the
the data to maximise server efficiency accross the entire organisation.

System Garden Harvest is a web service that reveals the hardware value 
locked inside your organisation, by analysing data from Habitat and other
system monitors. It delivers a long term archive for oranisation benchmarking
(comparing yours with other organisations), internal competition, 
system trending, cost estimation, power estimation, capacity management 
and other data analysis. Every part of the IT organisation benefits!
Take a look at http://www.systemgarden.com/harvest for more information.

Nigel Stuckey

System Garden Ltd
March 2010
nigel.stuckey@systemgarden.com
