SYSTEM GARDEN HABITAT
=====================

Version 1.0.0
=============

Welcome to System Garden Habitat, the monitoring, management and 
visualisation tool.

System Garden has released Habitat under the Free Software Foundation's 
Gnu Public License (GPL).   Please look at the file LICENSE in the 
top directory for a full description of the GPL and to understand 
the legal position.  Do not use this software unless you understand 
and agree to the license.

CHANGES
-------
This release includes the following changes over the 0.99.x series:- 


	VERSION 1.1
	- added home directory expansion (%u) for some route names
	- fixed several small problems with habmeth and habprobe
	- More tuning off log messages
	- Changed all apps to route_expand() entire config on initialisation
	- Job table changed to file, not ringstore to allow for easier
	  config changes in the future of the client
	- Non-time data (like job table) redraw bug fixed and update
	  routine refactored
	- Sanitised a number log messages to make more clear to user
	- Added authurl for proxy and site credentials (default ~/.habauth)
	- Added cookiejar for session token (default ~/.habjar)
	- Added cookies for account security (default ~/.habcookies) 
	- Added basic authentication for site security
	- Established communication with Harvest 2.0
	- Fixed a class of atoi() bug

	VERSION 1.0.0
	- Process instance identifier changed from pid to one made up from
	  the command and the pid, and called 'process'.
	- Added similar solaris human readable process id
	- Changed the solaris I/O probe id to be the mount point if one exists
	- Changed button text in log popup window to 'Close' from 'OK'
	- Route p-urls now default to plain files if driver is not supplied
	- Logo pixmap changed to have a mask
	- Log popup now has a window manager logo
	- Log collection pulldown added to log popup window
	- Added menu items and keyboard accelerators to zoom in and out
	  of graph in addition to buttons and mouse rubberbanding
	- Limited accumulated data to the timebase selected
	- Fixed a small bug when consolidated ringstore requests can return
	  two data for a single time
	- Fixed a memory allocation bug during updates when removing 
	  expired data
	- Graph redraws made more efficient by rationalising the work
	- Zoom menu item added and accelerator keys for charts
	- Choice tree popup added for general and node specific functions
	- Property window added with expert and inherited options
	- Added dynamic chocie node update

0.99.x CHANGES
--------------
For information, the collected changes in the 0.99.x series is as follows:-

	VERSION 0.99.6
	- Inventory of compressed man pages for RPM changed to .* to
	  allow RPMs to be built on mandrake and fedora
	- path simplification measures to more reliably find supporting 
	  files, like ghabitat's style (gtk rc)
	- improved exit messages from clockwork
	- More changes for solaris io probe to collect partition 
          information
	- Some makefile changes to cope with static and dynamic creation

	VERSION 0.99.5
	- lots of changes to linux ps probe: removed unavailable columns,
	  added linux specific ones, fixed calculation for others.
	- Library dependences cleared up in preparation for 
	  for an LSB version
	- Added a log popup in ghabitat from the status bar bomb button
	- Detailed logs working (column hiding) in ghabitat
	- Colourization of logs working in ghabitat
	- Severity of logs working in ghabitat
	- Dynamic logs now working in ghabitat
	- Tables now popup their records in separate windows when double
	  clicked in the viewing area in ghabitat
	- psolio changes to display full details on Solaris local storage
	- Solaris probes updated to remove depricated measurements
	- RPM post install script fixed following LSB changes
	- Fix to allow RPMs to be created under fedora

	VERSION 0.99.4
	- bug in enforcing maxes in sys probe fixed
	- reading csv formats fixed in ghabitat
	- reading text formats fixed in ghabitat
	- fixed a bug when refreshing of logs in ghabiat
	- max info values now honoured in graph displays of single and
	  multi instance charts in ghabiat -- great for percentages
	- fha, csv and text file information now displayed in ghabitat
	- if data is ok, can now display graphs from fha & csv files
	  in ghabitat
	- Fixed crashing bug on data sets without time
	- Added host information to 'this host' node in ghabitat
	- Added host information to nodes under 'my host' in ghabitat

	VERSION 0.99.3
	- fixed bug in Linux IO header block
	- added maxima for % calculations in probe: I/O and sys
	- limited % calculations to 100.0% in I/O and sys
	- RPMs now run as daemon user not root for extra security
	- lock file moved to /var/lib/habitat with data file as it 
	  can be written to be daemon
	- sys probe now called system, io now called storage, defaults 
	  changed
	- some ghabitat input field prompts brought up to date
	- a few icons in the choice tree juggled around
	- solaris I/O probe updated to have similar capabilities to linux
	  (although a couple of columns not yet calculated)
	- HTTP methods now report HTTP server errors directly
	- Fixed minor external library issue on Solaris
	- Key startup directories now saved in configuration table
	- %v added to route_expand for location of $HAB/var
	- replication config changed to use %v
	- HTTP posts give diagnositc logs & report server-side errors
	- Added -v flag to print version and exit
	- Help->About... now prints habitat version in popup
	- replication->state in choice tree of ghabitat now gives table 
          of values directly
	- logs->errors in choice tree of ghabitat removes the duration node
          (which is always 0) and has a 'ring,dur' label
	- Man pages fixed and -v flag put in; user man updated
	- Man pages for habprobe, habmeth and irs added
	- Ghabitat tables now have a title that reflects their contents
	- Help menu in ghabitat updated to give more clarity
	- Can now launch key manpages from ghabiat

	VERSION 0.99.2
	- GUI Logging level adjustable from Help menu
	- Zoom is not reset when curves are selected or deselected
	- Makefile now produces inventory for packaging
	- subcommands of 'change' added to irs: 'change name', 
	  'change duration', 'change about', 'change long' & 'change slots'
	- Added license file to src and bin tars
	- meth_relay() slowed down to 30 seconds to reduce system call impact
	- RPM generation added, initially for Mandrake, adding an INVENTORY
	  file and some menu code to launch ghabitat from the desktop.
	  Runs from /usr/bin locations, rather than clustered round a 
	  single dir
	- Detection of running in Linux system locations improved
	- Lock rendezvous much improved
	- Changed the initial display to look at 'this host'->'cpu' first
	- Fixed some memory leaks in clockwork
	- RPM now installs into rc?.d directories to autostart clockwork in
	  Red Hat and LSB compliant systems
	- Linux disk mount collection method changed: now gives a device 
	  name for /dev/root
	- default ghabitat display changed to 'this host->1 hour'
	- new, more descriptive label placed above charts
	- ordering changed in choice menu

	VERSION 0.99.1
	- psoldown probe change rtbuf to ROUTE and given linux usage text
	- elog and nmalloc classes use const to suppress warnings from gcc
	- this README added to src and bin distributions
	- gnu/Make.sub was replaced as it had the wrong contents
	- 'my services' and 'grouped services' removed to avoid confusion
	- more space around some GUI buttons for clarity
	- increased performance by only asking for new data in updates (^L)
	- fixed empty data transfer sometimes crashing the server
	- fixed graph redraw: new data is appended
	- when zoomed, dynamically updating of graphs is inhibited
	- IO probe (for disks) only reports active devices
	- linux IO service times now appearing (where available)
	- probe/Make.sub changed to avoid linking bug
	- new Solaris sys probe producing absolute values not counters
	  good for reuse; speed of calculation also addressed 
	- Moved 'this client' down the choice tree
	- Added a label above the chart to describe the location

	VERSION 0.99.0
	- the 'route' I/O system replaced with a more modular version
	- new storage method: ringstore added
	- habget, habput interface changed. 
          'Fat Headed Arrays' are now the default way to move data around
	- irs added to examine and manipulate ringstores
	- Holstore, tablestore, timestore and versionstore have been 
          deprecated
	- ihol, its, itab, iver management apps have been removed, 
          although the data will still be available
	- ispan has been removed
	- stat command added to irs to examine ring's status
	- full ringstore addressing supported (compatible with sqlrs)
	- mget added to irs to get several records at once
	- igdbm added to utils as a dev utility
	- formatting bug fixed in table
	- ringstore header storage made more sophisticated
	- cascade reimplemented to work on routes and tables and to
	  correctly sample multi-instance data. API changed, tests improved.
	- event class ported to ringstore and revised ROUTE semantics
	- runq class ported to new ROUTE
	- caching bug fixed in ringstore
	- man page for irs written
	- %d added to expand clockwork job names with duration
	- duration command added to irs to change duration within rings
	- increates the functions available to the sample method
	- standard names and data locations altered in clockwork's job table
	- ringstores added to ghabitat
	- direct scanning and display of .CSV and .FHA files in ghabitat
          using open->file. Appears under 'my files'
	- changed the meaning of the start value in job tables
	- consolidated ring store added as table and chart
	- selective display of logs and errors
	- job table added to the choice tree
	- simple view of uptime as a table added to choice tree
	- additional icons added to choice tree
	- some rings renamed dynamically to make more sense (eg io->disk)
	- some recognised rings get special icons (sys, io, net etc)
	- filter out known non-performance stats from perf branches
	- created simple utility to edit ring data: habedit
	- added /local to web service in clockwork, attached to local 
	  ringstore data.
	- 'this host' now working as a choice in the gui
	- 'my hosts' now able to pick up peer clockwork instances in
	  addition to repository hosts (File->Host)
	- save and restore selections under 'my hosts' to ~/.habrc
	- 'my files' and 'my hosts' save and restore entries separated
	- improved status messages when starting and stopping ghabitat,
	  useful if the user has to wait on net or i/o
	- removed File->Import and File->Export from ghabitat as csv'a can
	  be displayed and import/export is possible on command line
	- Added a scroll bar to the File->Close window
	- Added dynamic changing of logging level to ghabitat
	- Added manual pages to help menu
	- Pulldowns for history added to File->Host and File->Route
	- Comments and long names of ringstores made a sane length i


INSTALLATION
------------

Copy the Habitat tree into an area of read write disk, which will need
around 50 MBytes free (the directory is referred to as $HAB in this readme). 

Once copied, check that there is ~40 MBytes of available storage which 
will be used for the data file. There should be permissions to create files 
for the user that will run the system ($HAB/var is written to).

No environment variables need to be set.

Thats it!

HOW TO START
------------

Just run the command 'ghabitat' inside $HAB/bin, which will start the 
Gtk GUI. You will be asked if you want to start local collection of 
data via a pop-up window. Click 'Collect data', which will start the 
back-end server and load the file into your data choice pane on the left.
The data file created will have your ownership default umask.

In the current release, the default data collection rate is every 60 
seconds, which keeps the impact to system load to a minimum. 
Unfortunately, this means that you will need to wait for two to three 
minutes for meaningful data to appear.

The 'ghabitat' window is divided into two, like an `explorer' type interface. 
On the left is a tree of data choices, on the right is a visualisation of 
the data that you select.

Once you are ready to look at the data, look for 'this host' under the
choice tree on the left. (You can also see the data under 'my files' 
in the tree, named <hostname>.rs, which is the filename the into which
data has been stored). Look at 'perf charts' and 'perf tables'.
Under either option, you will find data gathered from at least five probes:

symbols    - OS name data (run once at start up)
system     - processor & general system information
storage    - disk performance
network    - network collection
interrupts - hardware interrupts

Click on 'cpu', click on a timebase and a graph or table will be generated 
in the visualisation area in the right hand pane.

The choice tree will look a little like this (or will after some time):-

habitat
|
+ this host
| + uptime
| + perf charts
| | + symbols
| | + system
| | | + 5 minutes
| | | + 1 hour
| | | + 8 hours
| | | + 24 hours
| | | + 7 days
| | | + 2 weeks
| | + storage
| | + network
| | + interrupts
| + perf tables
| + events
| + logs
| + replication
| + jobs
| + data
+ my files
+ my hosts
+ repository
+ this client
  + configuration
  + log routes
  + logs


Under 'this client', you find application configuration, error routing
under 'log routes' and the message themselves as 'logs'.

LOOKING AT THE DATA
-------------------

Using 'perf table', the data section shows a table which can be 
scrolled horizontally and vertically. The opportunity to save or send
the data in various forms is given by the Data menu.

With 'perf chart' options, the viewing section is divided in two
for the graph and the curve buttons. A default selection of curves are
drawn, such as %work or %system in the sys probe. To select more or 
less curves, just click on the buttons which will colour code the curves
that are drawm.

If a multi instance probe is selected, like io (for disks) or net, then
the button secition is itself divided in two: the bottom for buttons and 
the top for instances. For example, each disk device will be a different 
instance, but each will have the same attributes (such as blocks read or 
filesystem capacity).

A useful feature of the graphs is the ability to zoom in. Either use the 
button box to the top right to zoom in and out, or drag a box round the 
area of graph in interest, then click inside it to zoom.

RUNNING STAND ALONE
-------------------

Habitat consists of a back end for data gathering called 'clockwork'
and a set of front ends for display and analysis of results, of which the
most useful is 'ghabitat'. If 'ghabitat' finds that 'clockwork' is not
running on the local system, it will ask if you wish to run it and
optionally leave it running.

However, to collect data on several machines, just run 'clockwork'
on each machine, which as a daemon wil background itself and deal with 
its own errors for later management. The data is saved in a file named 
after the local system in a standard location accessable by file sharing 
(NFS, SMB/CIFS, etc), and also publish it using a network service.

If there is a problem launching clockwork, starting

          $HAB/bin/clockwork -d

will cause diagnostic messages to be sent to stderr. Send this output to 
support@systemgarden.com. If there are still problems, execute the 
following line in conjunction with System Garden's support (as there 
is lot of gory detail here):-

          $HAB/bin/clockwork -D

This places clockwork into developer debug mode.

This will send all messages to stderr on the screen, including debug
information which will help in the diagnosis of the problem. Send this
information to support@systemgarden.com, too.

WHERE DOES EVERYTHING GO?
-------------------------

By convention (and default), everything is read from and written to 
a single file

          $HAV/var/<yourhost>.rs

where <host> is the name of your computer, obatined by typing 
`hostname' at a command prompt. Depending on configuration, the file name
may also include the domainname.

Inside this file are rings of data, one of which is a log file (`log') and
another is a set of directives (`clockwork'). The directives have a section
of their own below, but for now lets look at the log.

The utility 'irs' can be used to look at this data, or the 'data' section
of the tree will give a view to the raw data.

All the parts of habitat are configured in the same way, using 
$HAB/etc/habitat.conf and ~/.habrc. It can also be augmented from 
more central locations: see the manual page habconf(5).

PERFORMANCE GATHERING PROBES
----------------------------

A probe is a small piece of code inside or called by the back end 
`clockwork'. Its job is to sample data and potentially repackage it
for data display.

Select `perf charts' and at least two children appear: `symbols' 
and `system'. These are the names of the active probes running from 
`clockwork' and each probe generates data which we can view in different 
ways. If you were to write a probe, it would appear here.

If an item in the list is selected, it will change colour and a curve 
drawn in that colour in the graph display. Selecting multiple items will 
display multiple curves in appropreate colours.

TO EXIT THE FRONT END
---------------------

Type ^X or click on `File->Exit' to leave the application.

STOPPING CLOKWORK NORMALLY AND WHAT TO EXPECT
---------------------------------------------

Clockwork is a daemon, detached from the command line.
As such, it is designed to stay runnning indefinitely, permanently 
recording your system's activities. There are no problems leaving it
to run as it always trys to curtail the amount to disk space used.

To stop clockwork from obtaining samples, use 'killclock'. This will 
find the lock file created from clockwork and attempts to send a
signal to the running process in order to end it.

From the 'ghabitat' GUI, select Collect->local Data... from the menu
and stop local data collection from the pop-up window.

OTHER COMMANDS
--------------
Other commands exists to complement the GUI and data collector.

	killclock - stop the clockwork daemon
	habrs     - command line interface to ringstore storage & admin
	habget    - get data from a route
	habput    - send data to a route
	habedit   - edit a route or ringstore (useful for configuring
	            the jobs in clockwork)
	habmeth   - run a clockwork method manually
	habprobe  - run one of the built-in data gathering 
	            probe manually
	habrep    - run the replication procedure manually

DOCUMENTATION & NEXT STEPS
--------------------------
To learn more about habitat, look at the System Garden web site 
http://www.systemgarden.com/habitat. It gives information about the product 
and company and is the place to go to for new downloads and documentation. 

By clicking on `documentation' under the `habitat' heading, you
get overviews, presentations, white papers and manuals. As more is
written, it will be placed there, so check back periodically.

HARVEST
-------
Enterprise level management is delivered by System Garden Harvest, 
a commercial web service that reveals the hardware value locked inside
your organisation. Harvest employs Habitat and other sources to populate
a long term archive for company benchmarking, internal compitition, 
service level reports, system trending, capacity management 
and other data analysis. Every part of the IT organisation benifits!
Take a look at http://www.systemgarden.com/harvest for more information.

Nigel Stuckey

System Garden Ltd
July 2005
nigel.stuckey@systemgarden.com
